{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age         workclass  fnlwgt   education  education-num  \\\n",
      "0   39         State-gov   77516   Bachelors             13   \n",
      "1   50  Self-emp-not-inc   83311   Bachelors             13   \n",
      "2   38           Private  215646     HS-grad              9   \n",
      "3   53           Private  234721        11th              7   \n",
      "4   28           Private  338409   Bachelors             13   \n",
      "\n",
      "        marital-status         occupation    relationship    race      sex  \\\n",
      "0        Never-married       Adm-clerical   Not-in-family   White     Male   \n",
      "1   Married-civ-spouse    Exec-managerial         Husband   White     Male   \n",
      "2             Divorced  Handlers-cleaners   Not-in-family   White     Male   \n",
      "3   Married-civ-spouse  Handlers-cleaners         Husband   Black     Male   \n",
      "4   Married-civ-spouse     Prof-specialty            Wife   Black   Female   \n",
      "\n",
      "   capital-gain  capital-loss  hours-per-week native-country  income  \n",
      "0          2174             0              40  United-States   <=50K  \n",
      "1             0             0              13  United-States   <=50K  \n",
      "2             0             0              40  United-States   <=50K  \n",
      "3             0             0              40  United-States   <=50K  \n",
      "4             0             0              40           Cuba   <=50K  \n"
     ]
    }
   ],
   "source": [
    "#importing packages\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#read the csv\n",
    "df = pd.read_csv(\"AdultData.csv\",sep = None, engine = 'python',header = None, decimal = '.', names = ['age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country','income' ]  )\n",
    "#read the columns \n",
    "df.dtypes\n",
    "#checking the count of the columns\n",
    "df.count()\n",
    "#checking age range first\n",
    "dfAge = df['age']\n",
    "dfAgeRangeCheck = dfAge.between(16,100)\n",
    "dfAgeRangeCheck[dfAgeRangeCheck[:] == False]\n",
    "#no value that is outside of range 16 and 100\n",
    "#Next to check the workclass\n",
    "df['workclass'].value_counts()\n",
    "#number of missing values\n",
    "mv=1836\n",
    "#remove whitespace\n",
    "df['workclass']=df['workclass'].str.strip()\n",
    "#total counts of dataset\n",
    "df.count()\n",
    "#calculate the percentage of missing values\n",
    "p = (1836.0/32561)\n",
    "#p=0.056 which means only 5.6% values have missed. It is very insignificant, so we will drop them\n",
    "df = df[df[\"workclass\"] != \"?\" ]\n",
    "# we can see that there are a few missing values\n",
    "#Next is fnlwgt\n",
    "dfFinalWeight = df['fnlwgt']\n",
    "df[df['fnlwgt'].isnull()]\n",
    "#continuous variable with no nulls\n",
    "#Next is education\n",
    "dfEducation = df['education']\n",
    "dfEducation.value_counts()\n",
    "#check No nulls\n",
    "df[dfEducation.isnull()]\n",
    "#no nulls next is education-num\n",
    "dfEducationNum = df['education-num']\n",
    "dfEducationNum.value_counts()\n",
    "#no null variables\n",
    "#Next is marital-status\n",
    "dfMaritalStatus = df['marital-status']\n",
    "dfMaritalStatus.value_counts()\n",
    "#no missing variables. Onto occupation\n",
    "df['occupation'].value_counts()\n",
    "#total number of missing values\n",
    "mv=mv+7\n",
    "#remove whitespace\n",
    "df['occupation']=df['occupation'].str.strip()\n",
    "#total counts of dataset\n",
    "df.count()\n",
    "#calculate the percentage of missing values\n",
    "p = (7.0/30725)\n",
    "#p=0.00022 which means only 5.6% values have missed. It is very insignificant, so we will drop them\n",
    "df = df[df[\"occupation\"] != \"?\" ]\n",
    "#next is relationship\n",
    "dfRelationship = df['relationship']\n",
    "dfRelationship.value_counts()\n",
    "#no missing values,\n",
    "#next we move onto race\n",
    "dfRace = df['race']\n",
    "dfRace.value_counts()\n",
    "#no missing values, so onto the next variable \n",
    "dfSex = df['sex']\n",
    "dfSex.value_counts()\n",
    "#no missing variables, so onto the next of capital-gain 0 or above\n",
    "dfCapitalGain = df['capital-gain']\n",
    "dfCapitalGainCheck = dfCapitalGain.between(0,999999)\n",
    "dfCapitalGainCheck[dfCapitalGainCheck[:] == False]\n",
    "#capital-loss check 0 or above\n",
    "dfCapitalLoss = df['capital-loss']\n",
    "dfCapitalLossCheck = dfCapitalLoss.between(0,999999)\n",
    "dfCapitalLossCheck[dfCapitalLossCheck[:] == False]\n",
    "#checking if hours per week is at least 0 and above\n",
    "dfHoursPerWeek = df['hours-per-week']\n",
    "dfHoursPerWeekCheck = dfHoursPerWeek.between(0,9999999)\n",
    "dfHoursPerWeekCheck[dfHoursPerWeekCheck[:] == False]\n",
    "#checking native countries, 556 records of '?' values\n",
    "df['native-country'].value_counts()\n",
    "#total number of missing values\n",
    "mv=mv+556\n",
    "#remove whitespace\n",
    "df['native-country']=df['native-country'].str.strip()\n",
    "#total counts of dataset, total records is 30178\n",
    "df.count()\n",
    "#calculate the percentage of missing values\n",
    "p = (556.0/30178)\n",
    "#p=0.0184 which means only 5.6% values have missed. It is very insignificant, so we will drop them\n",
    "df = df[df[\"native-country\"] != \"?\" ]\n",
    "print(df.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Without KFold cross validation and tweaking parameters\n",
      "test size 50%\n",
      "[[9589 1706]\n",
      " [1750 2036]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       <=50K       0.85      0.85      0.85     11295\n",
      "        >50K       0.54      0.54      0.54      3786\n",
      "\n",
      "   micro avg       0.77      0.77      0.77     15081\n",
      "   macro avg       0.69      0.69      0.69     15081\n",
      "weighted avg       0.77      0.77      0.77     15081\n",
      "\n",
      "Searching for highest cross validation score for depth between 3 and 50\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "abc = ['age', 'workclass', 'education', 'education-num', 'marital-status', 'occupation', 'relationship', 'race', 'sex','hours-per-week', 'native-country' ]\n",
    "#getting the specific attributes\n",
    "X = df.iloc[:,[0,1,3,4,5,6,7,8,9,12,13]].values\n",
    "#income attribute as the class label\n",
    "Z = pd.DataFrame(X)\n",
    "\n",
    "#T = df.iloc[:,[14]]\n",
    "\n",
    "\"\"\"X is 10 columns\n",
    "Age, workclass, education, education-num, marital-status, \n",
    "occupation, relationship, race, sex, hours-per-week, native-country,\n",
    "\"\"\"\n",
    "#import labelencoder  for converting categorical variables\n",
    "#to numerical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder_X = LabelEncoder()\n",
    "#column workclass\n",
    "X[:,1] = labelencoder_X.fit_transform(X[:,1])\n",
    "#column education\n",
    "X[:,2] = labelencoder_X.fit_transform(X[:,2])\n",
    "#column education-num\n",
    "X[:,3] = labelencoder_X.fit_transform(X[:,3])\n",
    "#column marital-status\n",
    "X[:,4] = labelencoder_X.fit_transform(X[:,4])\n",
    "#column occupation\n",
    "X[:,5] = labelencoder_X.fit_transform(X[:,5])\n",
    "#column relationship\n",
    "X[:,6] = labelencoder_X.fit_transform(X[:,6])\n",
    "#column race\n",
    "X[:,7] = labelencoder_X.fit_transform(X[:,7])\n",
    "#column sex\n",
    "X[:,8] = labelencoder_X.fit_transform(X[:,8])\n",
    "#column native-country\n",
    "X[:,10] = labelencoder_X.fit_transform(X[:,10])\n",
    "\n",
    "#new dataframe with categorical variables changed to numerical \n",
    "Z = pd.DataFrame(X)\n",
    "\n",
    "#getting all the feature columns\n",
    "feature_cols = [0,1,2,3,4,5,6,7,8,9,10]\n",
    "\n",
    "#A dataframe contains all the feature columns\n",
    "A = Z[feature_cols]\n",
    "\n",
    "#B contains the class label\n",
    "B = df['income']\n",
    "\n",
    "#convert into numpy array for decisiont tree classifier and validation\n",
    "featureA = A.values\n",
    "featureB = B.values\n",
    "\n",
    "\n",
    "print (\"\\n\\nWithout KFold cross validation and tweaking parameters\")\n",
    "print(\"test size 50%\")\n",
    "# Split dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(A, B, test_size=0.5, random_state=0)\n",
    "#running default tree classifier to see results \n",
    "clf = DecisionTreeClassifier(criterion='gini')\n",
    "\n",
    "fit = clf.fit(X_train, y_train)\n",
    "y_pre = fit.predict(X_test)\n",
    "\n",
    "\n",
    "#displa y confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pre)\n",
    "print cm\n",
    "\n",
    "#display classification report\n",
    "from sklearn.metrics import classification_report\n",
    "print classification_report(y_test, y_pre)\n",
    "\n",
    "\n",
    "\n",
    "#CONTINUE EXPLORING FROM HERE DEPTH\n",
    "#************************************************************************************************************\n",
    "\n",
    "print(\"Searching for highest cross validation score for depth between 3 and 50\")\n",
    "train_X, test_X, train_y, test_y = train_test_split(featureA,featureB,test_size = 0.5)\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#loop from 3 to 50, changing the max depth and running through a cross validation score with 10 folds\n",
    "#here we get the mean and add to a depthvalue list\n",
    "#we attempt to find the best depth for use as our parameter\n",
    "depthValue = []\n",
    "for i in range(3,50):\n",
    "    dTC = DecisionTreeClassifier(max_depth = i)\n",
    "    scores = cross_val_score(dTC, train_X, train_y, cv = 10, n_jobs = 4)\n",
    "    depthValue.append((scores.mean()))\n",
    "    \n",
    "#plotting a density graph on the cross validation score to determine\n",
    "#the best max value\n",
    "plt.plot(range(3,50),depthValue)\n",
    "plt.xlabel('Max Depth')\n",
    "plt.xticks(np.arange(3, 50, 1.0))\n",
    "plt.ylabel('Cross Validation-Score')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "maxDepthIndex = depthValue.index(max(depthValue))\n",
    "#assigning variable for final prediction index\n",
    "print \"Index: \" +str(maxDepthIndex+3) \n",
    "print(\"Cross Validation Score: \" + str(depthValue[maxDepthIndex]))\n",
    "#the actual depth for assigning later\n",
    "bestDepthValue = maxDepthIndex+3\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#MIN SAMPLES SPLIT\n",
    "print \"Searching for highest cross validation score for a certain min samples split between 0 and 300\"\n",
    "train_X, test_X, train_y, test_y = train_test_split(featureA,featureB,test_size = 0.5)\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#same thing with the depth but on the minimum samples split\n",
    "minSampleValue = []\n",
    "for i in range(3,300):\n",
    "    dTC = DecisionTreeClassifier( min_samples_split = i)\n",
    "    scores = cross_val_score(dTC, train_X, train_y, cv = 10, n_jobs = 4)\n",
    "    minSampleValue.append((scores.mean()))\n",
    "    \n",
    "plt.plot(range(3,300),minSampleValue)\n",
    "plt.xlabel('min samples split')\n",
    "plt.xticks(np.arange(3, 300, 5)) \n",
    "plt.ylabel('Cross Validation-Score')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "minIndex = minSampleValue.index(max(minSampleValue))\n",
    "print \"Index: \"+ str(minIndex+3)\n",
    "print(\"Cross Validation Score: \" + str(minSampleValue[minIndex]))\n",
    "\n",
    "\n",
    "#assigning variable for final prediction min samples split\n",
    "bestMinSamplesSplitValue = minIndex + 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#With new parameters \n",
    "print (\"\\n\\nWith Tweaked paramters\")\n",
    "# Split dataset into training set and test set 50%\n",
    "X_train, X_test, y_train, y_test = train_test_split(featureA, featureB, test_size=0.5, random_state=0)\n",
    "clf = DecisionTreeClassifier(criterion='gini', max_depth = bestDepthValue, min_samples_split = bestMinSamplesSplitValue)\n",
    "\n",
    "fit = clf.fit(X_train, y_train)\n",
    "y_pre = fit.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pre)\n",
    "print cm\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print classification_report(y_test, y_pre)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CONTINUE EXPLORING FROM HERE DEPTH\n",
    "#************************************************************************************************************\n",
    "\n",
    "print(\"Searching for highest cross validation score for depth between 3 and 50\")\n",
    "print \"Test Size: 40%\"\n",
    "train_X, test_X, train_y, test_y = train_test_split(featureA,featureB,test_size = 0.4)\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#loop from 3 to 50, changing the max depth and running through a cross validation score with 10 folds\n",
    "#here we get the mean and add to a depthvalue list\n",
    "#we attempt to find the best depth for use as our parameter\n",
    "depthValue = []\n",
    "for i in range(3,50):\n",
    "    dTC = DecisionTreeClassifier(max_depth = i)\n",
    "    scores = cross_val_score(dTC, train_X, train_y, cv = 10, n_jobs = 4)\n",
    "    depthValue.append((scores.mean()))\n",
    "    \n",
    "#plotting a density graph on the cross validation score to determine\n",
    "#the best max value\n",
    "plt.plot(range(3,50),depthValue)\n",
    "plt.xlabel('Max Depth')\n",
    "plt.xticks(np.arange(3, 50, 1.0))\n",
    "plt.ylabel('Cross Validation-Score')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "maxDepthIndex = depthValue.index(max(depthValue))\n",
    "#assigning variable for final prediction index\n",
    "print \"Index: \" +str(maxDepthIndex+3) \n",
    "print(\"Cross Validation Score: \" + str(depthValue[maxDepthIndex]))\n",
    "#the actual depth for assigning later\n",
    "bestDepthValue = maxDepthIndex+3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MIN SAMPLES SPLIT\n",
    "print \"Searching for highest cross validation score for a certain min samples split between 0 and 300\"\n",
    "train_X, test_X, train_y, test_y = train_test_split(featureA,featureB,test_size = 0.4)\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#same thing with the depth but on the minimum samples split\n",
    "minSampleValue = []\n",
    "for i in range(3,300):\n",
    "    dTC = DecisionTreeClassifier( min_samples_split = i)\n",
    "    scores = cross_val_score(dTC, train_X, train_y, cv = 10, n_jobs = 4)\n",
    "    minSampleValue.append((scores.mean()))\n",
    "    \n",
    "plt.plot(range(3,300),minSampleValue)\n",
    "plt.xlabel('min samples split')\n",
    "plt.xticks(np.arange(3, 300, 5)) \n",
    "plt.ylabel('Cross Validation-Score')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "minIndex = minSampleValue.index(max(minSampleValue))\n",
    "print \"Index: \"+ str(minIndex+3)\n",
    "print(\"Cross Validation Score: \" + str(minSampleValue[minIndex]))\n",
    "\n",
    "\n",
    "#assigning variable for final prediction min samples split\n",
    "bestMinSamplesSplitValue = minIndex + 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#With new parameters \n",
    "print (\"\\n\\nWith Tweaked paramters\")\n",
    "# Split dataset into training set and test set 40%\n",
    "X_train, X_test, y_train, y_test = train_test_split(featureA, featureB, test_size=0.4, random_state=0)\n",
    "clf = DecisionTreeClassifier(criterion='gini', max_depth = bestDepthValue, min_samples_split = bestMinSamplesSplitValue)\n",
    "\n",
    "fit = clf.fit(X_train, y_train)\n",
    "y_pre = fit.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pre)\n",
    "print cm\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print classification_report(y_test, y_pre)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CONTINUE EXPLORING FROM HERE DEPTH\n",
    "#************************************************************************************************************\n",
    "\n",
    "print(\"Searching for highest cross validation score for depth between 3 and 50\")\n",
    "print \"Test Size: 20%\"\n",
    "train_X, test_X, train_y, test_y = train_test_split(featureA,featureB,test_size = 0.2)\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#loop from 3 to 50, changing the max depth and running through a cross validation score with 10 folds\n",
    "#here we get the mean and add to a depthvalue list\n",
    "#we attempt to find the best depth for use as our parameter\n",
    "depthValue = []\n",
    "for i in range(3,50):\n",
    "    dTC = DecisionTreeClassifier(max_depth = i)\n",
    "    scores = cross_val_score(dTC, train_X, train_y, cv = 10, n_jobs = 4)\n",
    "    depthValue.append((scores.mean()))\n",
    "    \n",
    "#plotting a density graph on the cross validation score to determine\n",
    "#the best max value\n",
    "plt.plot(range(3,50),depthValue)\n",
    "plt.xlabel('Max Depth')\n",
    "plt.xticks(np.arange(3, 50, 1.0))\n",
    "plt.ylabel('Cross Validation-Score')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "maxDepthIndex = depthValue.index(max(depthValue))\n",
    "#assigning variable for final prediction index\n",
    "print \"Index: \" +str(maxDepthIndex+3) \n",
    "print(\"Cross Validation Score: \" + str(depthValue[maxDepthIndex]))\n",
    "#the actual depth for assigning later\n",
    "bestDepthValue = maxDepthIndex+3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MIN SAMPLES SPLIT\n",
    "print \"Searching for highest cross validation score for a certain min samples split between 0 and 300\"\n",
    "train_X, test_X, train_y, test_y = train_test_split(featureA,featureB,test_size = 0.2)\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#same thing with the depth but on the minimum samples split\n",
    "minSampleValue = []\n",
    "for i in range(3,300):\n",
    "    dTC = DecisionTreeClassifier( min_samples_split = i)\n",
    "    scores = cross_val_score(dTC, train_X, train_y, cv = 10, n_jobs = 4)\n",
    "    minSampleValue.append((scores.mean()))\n",
    "    \n",
    "plt.plot(range(3,300),minSampleValue)\n",
    "plt.xlabel('min samples split')\n",
    "plt.xticks(np.arange(3, 300, 5)) \n",
    "plt.ylabel('Cross Validation-Score')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "minIndex = minSampleValue.index(max(minSampleValue))\n",
    "print \"Index: \"+ str(minIndex+3)\n",
    "print(\"Cross Validation Score: \" + str(minSampleValue[minIndex]))\n",
    "\n",
    "\n",
    "#assigning variable for final prediction min samples split\n",
    "bestMinSamplesSplitValue = minIndex + 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#With new parameters \n",
    "print (\"\\n\\nWith Tweaked paramters\")\n",
    "# Split dataset into training set and test set 40%\n",
    "X_train, X_test, y_train, y_test = train_test_split(featureA, featureB, test_size=0.2, random_state=0)\n",
    "clf = DecisionTreeClassifier(criterion='gini', max_depth = bestDepthValue, min_samples_split = bestMinSamplesSplitValue)\n",
    "\n",
    "fit = clf.fit(X_train, y_train)\n",
    "y_pre = fit.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pre)\n",
    "print cm\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print classification_report(y_test, y_pre)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
